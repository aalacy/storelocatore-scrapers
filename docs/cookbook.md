# Crawl Cookbook
> The canonical source of best practices in writing crawlers/scrapers

## Table of Contents

### Templates
* [Template types and uses](./cookbook/templates.md)

### Basics
* [Git Workflow](./cookbook/git_workflow.md)
* [Directory & File Skeleton](./cookbook/dir_skeleton.md)
* [Generating a Python requirements file](./cookbook/reqfile.md)
* [External Logging documentation](https://docs.google.com/document/d/1I-1Atok4pd1RKW_ZfRzv7rMnuYTV0R_yo8QMnCSdwdE/view).

### Fetching data
* [TODO] Request anything over HTTP
* [TODO] Parse JSON results
* [TODO] Parse XML results
* [TODO] Parse HTML results
* [TODO] Traverse paginated content
* [TODO] Requests that are very slow

### Using Zipcodes / Coordinates 
* See our [external `sgzip` documentation](https://docs.google.com/document/d/1vop1cL_t38IYbCiwt2eYl8s3yujbpVwfniLiSqhsR8w/view)
* [TODO] When to use a static vs dynamic list?
* [TODO] Using a static zipcode / coordinate list [TODO]
* [TODO] Using a dynamic zipcode / coordinate list [TODO]

### Declarative Pipeline
* [Using the Declarative Field Mapping](./cookbook/declarative_pipeline.md)

### Misc [TODO]
* ...


