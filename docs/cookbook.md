# Crawl Cookbook

> The canonical source of best practices in writing crawlers/scrapers

## Table of Contents

### Templates

- [Experimental Live Realtime Templating Engine](./cookbook/crawly_web.md)
- [Template types and uses](./cookbook/templates.md)

### Basics

- [Git Workflow](./cookbook/git_workflow.md)
- [Directory & File Skeleton](./cookbook/dir_skeleton.md)
- [Generating a Python requirements file](./cookbook/reqfile.md)
- [External Logging documentation](https://docs.google.com/document/d/1I-1Atok4pd1RKW_ZfRzv7rMnuYTV0R_yo8QMnCSdwdE/view).
- [Pausing and Resuming a Long-Running Crawl](./cookbook/pause_resume.md)

### Fetching data

- [TODO] Request anything over HTTP
- [TODO] Parse JSON results
- [TODO] Parse XML results
- [TODO] Parse HTML results
- [TODO] Traverse paginated content
- [TODO] Requests that are very slow

### Using Zipcodes / Coordinates

- See our [external `sgzip` documentation](https://docs.google.com/document/d/1vop1cL_t38IYbCiwt2eYl8s3yujbpVwfniLiSqhsR8w/view)
- [TODO] When to use a static vs dynamic list?
- [TODO] Using a static zipcode / coordinate list [TODO]
- [TODO] Using a dynamic zipcode / coordinate list [TODO]

### Declarative Pipeline

- [Using the Declarative Field Mapping](./cookbook/declarative_pipeline.md)

### Misc [TODO]

- ...
